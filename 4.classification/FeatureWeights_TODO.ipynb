{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contextualizes accuracy against a majority class baseline, and analyzes the most important features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            label=cols[0]\n",
    "            # sample text is already tokenized; if yours is not, do so here\n",
    "            text=cols[1] ## Note: I didn't end up tokenizing here because later countVectorizer takes raw string\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the directory with your data (from the CheckData_TODO.ipynb exercise).  \n",
    "# The directory should contain train.tsv, dev.tsv and test.tsv\n",
    "directory=\"../data/text_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY=read_data(\"%s/train.tsv\" % directory)\n",
    "devX, devY=read_data(\"%s/dev.tsv\" % directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Implement the majority class baseline for your data that we went over in `Hyperparameters.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(trainY, devY):\n",
    "    # your code here\n",
    "    \n",
    "    classes = pd.Series(trainY).value_counts().index\n",
    "    major_class =  pd.Series(trainY).value_counts().index[0] if (pd.Series(trainY).value_counts())[0] > (pd.Series(trainY).value_counts())[1] else trainY.value_counts().index[1] \n",
    "    \n",
    "    ## calculate accuracy\n",
    "    pred_table = pd.DataFrame({\"pred\": major_class,\n",
    "                               \"label\": devY})\n",
    "    pred_table['correct']= pred_table.pred == pred_table.label\n",
    "    \n",
    "    num_correct = pred_table.correct.value_counts()[True]\n",
    "    accuracy = num_correct/pred_table.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.484"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_class(trainY,devY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: After experimenting with hyperparameter choices in class, what is the best accuracy that you uncovered on your development data?  Which hyperparameter choices led to that accuracy?  Plug in the values here and execute the cell to yield the accuracy. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The best accuracy I got is 0.604 with a model with 10,000 features (vocab size) and inverse regularization parameter equals to 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"_NEWLINE_\", \" \")\n",
    "    text = text.replace(\"_TAB_\", \" \")\n",
    "    text = re.sub(r\"(?:https?:\\S+)\", \"\", text)\n",
    "    text = \" \".join(nltk.word_tokenize(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = list(map(preprocess, trainX))\n",
    "devX = list(map(preprocess, devX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.604\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "Y_train=le.transform(trainY)\n",
    "Y_dev=le.transform(devY)\n",
    "\n",
    "# split the string on whitespace because we assume it has already been tokenized\n",
    "vectorizer = CountVectorizer(max_features=10000, analyzer=str.split, lowercase=False, strip_accents=None, binary=True)\n",
    "\n",
    "X_train = vectorizer.fit_transform(trainX)\n",
    "X_dev = vectorizer.transform(devX)\n",
    "logreg = linear_model.LogisticRegression(C=5, solver='lbfgs', penalty='l2')\n",
    "model=logreg.fit(X_train, Y_train)\n",
    "print(\"Accuracy: %.3f\" % logreg.score(X_dev, Y_dev))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: For binary classification using logistic regression, the parameters of the learned model are given in `model.coef_[0]`.  Print out the 25 features that are most associated with each class (i.e., the 25 parameters that have the largest positive values and the 25 parameters with largest negative values).  For reference, consider the `inverse_transform` function in [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder.transform) to get the class labels that correspond to positive(=1) and negative(=0), and the `vocabulary_` function in [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to yield the index for each vocabulary term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_weights(learned_model, label_encoder, count_vectorizer):\n",
    "    # your code here\n",
    "    if pd.Series(Y_dev).value_counts().index[0] == 0:\n",
    "        pos_class = pd.Series(le.inverse_transform(Y_dev)).value_counts().index[1]\n",
    "        neg_class = pd.Series(le.inverse_transform(Y_dev)).value_counts().index[0]\n",
    "    else:\n",
    "        pos_class = pd.Series(le.inverse_transform(Y_dev)).value_counts().index[0]\n",
    "        neg_class = pd.Series(le.inverse_transform(Y_dev)).value_counts().index[1]\n",
    "        \n",
    "    feature_table = pd.DataFrame({\"vocab\": list(count_vectorizer.vocabulary_.keys()),\n",
    "                                 \"coef\": list(learned_model.coef_[0])})\n",
    "    sorted_tbl = feature_table.sort_values(\"coef\")\n",
    "    num_example = 25\n",
    "    print(\"***Most indicative of %s:\" % neg_class)\n",
    "    \n",
    "    for i in range(num_example):\n",
    "        print(\"%s : %s\" % (sorted_tbl.iloc[i,].vocab, sorted_tbl.iloc[i,].coef))\n",
    "    \n",
    "    print(\"\\n***Most indicative of %s:\" % pos_class)\n",
    "    for i in range(num_example):\n",
    "        print(\"%s : %s\" % (sorted_tbl.iloc[-(i+1),].vocab, sorted_tbl.iloc[-(i+1),].coef))\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Most indicative of female:\n",
      "cuban : -2.7776604888510605\n",
      "connect : -2.6684411415710656\n",
      "Luiy : -2.5223663585854856\n",
      "äìî¥Ÿ_ôÖ_ : -2.457317325795894\n",
      "productivity : -2.3859072586970136\n",
      "TheFoursBar : -2.3301905976389934\n",
      "_ôÖ‰_ôÖ‰ : -2.2156273495385093\n",
      "Expect : -2.1923208167671002\n",
      "Lockup : -2.1792412822869416\n",
      "gradually : -2.153857759777557\n",
      "Spotify : -2.1210152635398045\n",
      "SaccWhack : -2.107796295753613\n",
      "resolutioncomplete : -2.081467834658541\n",
      "civil : -2.056021933786774\n",
      "trip : -2.053072173318958\n",
      "1/26 : -2.041208367309916\n",
      "STORY : -1.9933183836582529\n",
      "manly : -1.9920504013133007\n",
      "announcements : -1.9480358133325983\n",
      "charities : -1.9447137321564663\n",
      "delivery : -1.9246644514904652\n",
      "Hass_Dinerroo : -1.909367400886759\n",
      "regs : -1.9036663939715572\n",
      "Discover : -1.8495071095273072\n",
      "BJJ : -1.843915708085739\n",
      "\n",
      "***Most indicative of male:\n",
      "somehow : 2.844051864237782\n",
      "shoplift : 2.785507222774734\n",
      "NewYearsResolution.. : 2.5506861320265535\n",
      "August : 2.3705265270440536\n",
      "attract : 2.317958348064095\n",
      "manner : 2.2887254448366865\n",
      "slurpslurp : 2.2732509761911963\n",
      "ICYMI : 2.2469302623969907\n",
      "hidden : 2.2181190580242207\n",
      "must : 2.181036893200366\n",
      "AssaultTriffle : 2.1759499676813356\n",
      "trick : 2.169846757134726\n",
      "realisticresolutions : 2.169658392363707\n",
      "fullest : 2.1686289050100296\n",
      "center : 2.1230974484762837\n",
      "emilieeharris : 2.078059738083824\n",
      "clears : 2.076498294394022\n",
      "keepitreal : 2.055238349201794\n",
      "phone : 2.050895616504726\n",
      "Im : 2.0507076117769016\n",
      "-Read : 2.0501518613843466\n",
      "organized : 2.0495194669814256\n",
      "VicarKelly : 2.025828702386399\n",
      "ruh-roh : 2.021837263580978\n",
      "fixed : 2.0170153919101925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "analyze_weights(model, le, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
