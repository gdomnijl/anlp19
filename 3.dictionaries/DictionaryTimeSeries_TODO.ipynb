{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the use of dictionaries for counting the frequency of some category of words in text, using sentiment (from the [AFINN sentiment lexicon](http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010)) in the time series data of tweets as an example.\n",
    "\n",
    "This notebook uses data from the AFINN sentiment lexicon; for other dictionaries in wide use, see [MPQA](https://mpqa.cs.pitt.edu/lexicons/subj_lexicon/) (free for use with registration) and [LIWC](http://liwc.wpengine.com) (commercial).\n",
    "\n",
    "Before running this notebook, install pandas:\n",
    "\n",
    "```sh\n",
    "source activate anlp\n",
    "conda install pandas=0.24.0\n",
    "conda install matplotlib=3.0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in json file of tweets and return a list of (date, tokenized text)\n",
    "def read_tweets_from_json(filename):\n",
    "    \n",
    "    tweets=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        data=json.load(file)\n",
    "        for tweet in data:\n",
    "            created_at=tweet[\"created_at\"]\n",
    "            date = pd.to_datetime(created_at)\n",
    "            text=tweet[\"text\"]\n",
    "            tokens=nltk.casual_tokenize(text)\n",
    "            tweets.append((date, tokens))\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of (date, tokens) tweets and count whether each tweet contains \n",
    "# a (lowercased) term in the argument dictionary.  Return as pandas dataframe\n",
    "# for easier slicing/plotting)\n",
    "def dictionary_document_count(data, dictionary):\n",
    "    counted=[]\n",
    "    for date, tokens in data:\n",
    "        val=0\n",
    "        for word in tokens:\n",
    "            if word.lower() in dictionary:\n",
    "                val=1\n",
    "        counted.append((date, val))\n",
    "    df=pd.DataFrame(counted, columns=['date','document frequency'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=read_tweets_from_json(\"../data/trump_tweets.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll define our own \"immigration\" dictionary by selecting words that we hypothesize are often found in the topic of immigration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_dictionary=set([\"wall\", \"border\", \"borders\", \"immigrants\",\"immigration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=dictionary_document_count(tweets, immigration_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time(counts):\n",
    "    \n",
    "    # for this exercise, let's just keep tweets published after 2015\n",
    "    counts=counts[(counts['date'] > '2015-01-01')]\n",
    "    \n",
    "    # counts is a pandas dataframe; let's aggregate the counts by month.  \n",
    "    # Can also aggregate by \"D\" for day, \"W\" for week, \"Y\" for year.\n",
    "    means=counts.resample('M', on='date').mean() \n",
    "    \n",
    "    means.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to run this command twice if you get a warning\n",
    "plot_time(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: The AFINN dictionary is a sentiment lexicon, where words are rated on a five-point affect scale (-5 = most negative, 5 = most positive).  Write a function `read_AFINN_dictionary` to read in this file and create two dictionaries like that above -- one for positive terms and one for negative terms.  How did you decide the cutoff point for positive and negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_AFINN_dictionary(filename):\n",
    "    positive=[]\n",
    "    negative=[]\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return set(positive), set(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive, negative=read_AFINN_dictionary(\"../data/AFINN-111.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Create a plot (like that above) using the negative sentiment dictionary you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=dictionary_document_count(tweets, negative)\n",
    "plot_time(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Create a new dictionary of your own for a concept you'd like to measure in `trump_tweets.json` or `aoc_tweets.json`.  The dictionary must contain at least 10 terms; you're free to create one for any category (except sentiment!), so be creative--we'll be comparing these in class on Thursday. Create a plot using that dictionary and data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 (check-plus): for each of the terms in your dictionary, write a function `print_examples(tweets, dictionary)` to find one tweet that contains that term and print it out for your inspection.  Is that term used in the same sense you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(tweets, dictionary):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_examples(tweets, immigration_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
